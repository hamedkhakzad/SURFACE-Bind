{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06eac428",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = '/work/lpdi/users/khakzad/Surfacome/database/dataset_surfaces.pt'\n",
    "pdb_data = '/work/lpdi/users/khakzad/Surfacome/pdbs/target_list_1_chopped/'\n",
    "pointcloud_results = '/work/lpdi/users/khakzad/Surfacome/pdbs/target_list_1_pointcloud/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc154c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d696bcffd845b9a20b32ecdcf06564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nglview as ng\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from nglview.color import ColormakerRegistry\n",
    "from pdbparser.pdbparser import pdbparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98e5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(prediction_data, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16eb6e",
   "metadata": {},
   "source": [
    "## Test on all proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00afe42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P26992 centroids:  [201, 135, 86]\n",
      "P15509 centroids:  [87, 338]\n",
      "Q99062 centroids:  [636, 616, 507, 409, 262]\n",
      "P19235 centroids:  [296, 260, 153, 38]\n",
      "P10912 centroids:  [213, 59, 7, 277]\n",
      "Q14626 centroids:  [379, 144, 254]\n",
      "P42701 centroids:  [561, 347, 280, 107]\n",
      "Q99665 centroids:  [637, 498, 411, 253, 15, 119]\n",
      "P78552 centroids:  [385, 359, 276, 89, 45]\n",
      "Q14627 centroids:  [97, 146, 352]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/lpdi/users/khakzad/Surfacome/\")\n",
    "from data import Protein\n",
    "from tqdm import tqdm\n",
    "from IPython.utils import io\n",
    "\n",
    "metrics = []\n",
    "stop=0\n",
    "for item in data:\n",
    "    if stop < 10:\n",
    "        stop+=1\n",
    "        # initializing all the outputs that we are going to produce per protein and store in the dictionary\n",
    "        sequence = []\n",
    "        sasa = []\n",
    "        point2residue = []\n",
    "        residue_number = []\n",
    "        no_binding_sites = 0\n",
    "        filtered_site_points = []\n",
    "        normalized_labels = []\n",
    "        cluster_for_all_points = []\n",
    "\n",
    "        acc = item['acc']\n",
    "        coords = item['coords']\n",
    "        embeddings = item['embeddings']\n",
    "        labels = item['label']\n",
    "\n",
    "        target_pdb = os.path.join(pdb_data,acc+\"_cropped.pdb\")\n",
    "\n",
    "        with io.capture_output() as captured:\n",
    "            protein = Protein(acc, coords, embeddings, labels, target_pdb, 0.7, 'cpu')\n",
    "\n",
    "            sequence = protein.get_sequence()\n",
    "            sasa = protein.get_sasa()\n",
    "            point2residue, residue2coords, residue_number = protein.point2residue()\n",
    "            no_binding_sites, filtered_site_points, normalized_labels, cluster_for_all_points = protein.clustering_labels()\n",
    "        \n",
    "        ## Calculating and adding the area based on above information\n",
    "        NUM_POINTS_THRESHOLD = 200\n",
    "        AREA_A2 = []\n",
    "        AREA_P = []\n",
    "        SEQ_COMP = []\n",
    "        centroids = []\n",
    "        i = 0\n",
    "        for clus in range(no_binding_sites-1):\n",
    "            seq_composition = []\n",
    "            cluster = torch.where(cluster_for_all_points==i+1)\n",
    "            i+=1\n",
    "            if len(cluster[0]) > NUM_POINTS_THRESHOLD:\n",
    "                cluster2residue = point2residue[cluster[0]]\n",
    "                INDEX = torch.unique(cluster2residue)\n",
    "                clustercoords = residue2coords[INDEX]\n",
    "\n",
    "                # calculate the centorid\n",
    "                centroid_of_cluster = np.mean(clustercoords.numpy(), axis=0)                \n",
    "                tmp = torch.tensor([[centroid_of_cluster[0], centroid_of_cluster[1], centroid_of_cluster[2]]])\n",
    "                dist = torch.cdist(clustercoords, tmp, p=2)\n",
    "                # calculate the closest point to the centroid\n",
    "                centroid_point = clustercoords[torch.argmin(dist)]\n",
    "                # calculate the closest residue\n",
    "                distances_allvsall = torch.norm(centroid_point - residue2coords, dim=-1)\n",
    "                distances_min = torch.argmin(distances_allvsall, dim=0)\n",
    "                centroids.append(residue_number[distances_min.item()])\n",
    "\n",
    "                area = 0\n",
    "                for idx in INDEX:\n",
    "                    area += sasa[idx+1]\n",
    "                    seq_composition.append(f'{residue_number[idx]}_{sequence[idx]}')\n",
    "\n",
    "                # print(\"area by summing up SASA:\", area, \"A^2\") \n",
    "                # print(\"area by considering number of points:\", len(cluster[0]))\n",
    "\n",
    "                AREA_A2.append(area)\n",
    "                AREA_P.append(len(cluster[0]))\n",
    "                SEQ_COMP.append({\"cluster_\"+str(i+1): seq_composition})\n",
    "        # print(residue_number)\n",
    "        print(acc, 'centroids: ', centroids)\n",
    "        metrics.append({'acc': acc,\n",
    "                        'sequence': sequence,\n",
    "                        'sasa': sasa,\n",
    "                        'point2residue': point2residue.numpy(),\n",
    "                        'no_binding_sites': no_binding_sites,\n",
    "                        'filtered_site_points': filtered_site_points.numpy(),\n",
    "                        'normalized_labels': normalized_labels,\n",
    "                        'cluster_for_all_points': cluster_for_all_points.numpy(),\n",
    "                        'area_angstrom2': AREA_A2,\n",
    "                        'area_points': AREA_P,\n",
    "                        'sequence_compositions_all_clusters': SEQ_COMP,\n",
    "                        'centroids': centroids})\n",
    "\n",
    "    #     tt = cluster_for_all_points.numpy()\n",
    "    #     norm_label_for_presentation = (tt-min(tt))/(max(tt)-min(tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837225a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame(metrics).to_csv('/work/lpdi/users/khakzad/Surfacome/database/result_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06511ee4",
   "metadata": {},
   "source": [
    "## How many binding site each protein has? and what is their area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d23971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "NUM_POINTS_THRESHOLD = 200\n",
    "metrics_area = []\n",
    "for eachProtein in metrics:\n",
    "    AREA_A2 = []\n",
    "    AREA_P = []\n",
    "    i = 0\n",
    "\n",
    "    accP = eachProtein['acc']\n",
    "    XX = eachProtein['cluster_for_all_points']\n",
    "    YY = eachProtein['point2residue']\n",
    "    SASA = eachProtein['sasa']\n",
    "\n",
    "    NUM_CLUSTERS = eachProtein['no_binding_sites']\n",
    "    for clus in range(NUM_CLUSTERS-1):\n",
    "        cluster = torch.where(XX==i+1)\n",
    "        i+=1\n",
    "        if len(cluster[0]) > NUM_POINTS_THRESHOLD:\n",
    "            cluster2residue = YY[cluster[0]]\n",
    "            INDEX = torch.unique(cluster2residue)\n",
    "            area = 0\n",
    "            for idx in INDEX:\n",
    "                area += SASA[idx+1]\n",
    "\n",
    "            print(\"area by summing up SASA:\", area, \"A^2\") \n",
    "            print(\"area by considering number of points:\", len(cluster[0]))\n",
    "\n",
    "            AREA_A2.append(area)\n",
    "            AREA_P.append(len(cluster[0]))\n",
    "\n",
    "    metrics_area.append({'acc': accP,\n",
    "                        'area_angstrom2': AREA_A2,\n",
    "                        'area_points':AREA_P})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ce0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_area).to_csv('/work/lpdi/users/khakzad/Surfacome/database/result_metrics_area.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040dae03",
   "metadata": {},
   "source": [
    "## Loading the file from drive and make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_area = pd.read_csv('/work/lpdi/users/khakzad/Surfacome/database/result_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_area['area_angstrom2'] = result_area['area_angstrom2'].apply(ast.literal_eval)\n",
    "result_area['area_points'] = result_area['area_points'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding some threshold for the size of detected clusters\n",
    "## if it's too small, delete it. (it's now added into the main analysis!)\n",
    "import ast\n",
    "all_area_angstrom = []\n",
    "all_area_points = []\n",
    "all_area_BI_no = []\n",
    "for index, row in result_area.iterrows():\n",
    "    BI_no = 0\n",
    "    for i, item in enumerate(row['area_points']):\n",
    "        if item > 100:\n",
    "            BI_no += 1\n",
    "            all_area_points.append(item)\n",
    "            all_area_angstrom.append(row['area_angstrom2'][i])\n",
    "    all_area_BI_no.append(BI_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(all_area_angstrom, bins=np.linspace(0, 10000, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(all_area_BI_no, bins=len(all_area_BI_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cef967",
   "metadata": {},
   "source": [
    "## Representing some clustering results in the form of pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_metrics = pd.read_csv('/work/lpdi/users/khakzad/Surfacome/database/result_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    " \n",
    "filename = '/work/lpdi/users/khakzad/Surfacome/database/result_metrics.csv'\n",
    "\n",
    "data = open(filename, 'r')\n",
    "metrics_data = csv.DictReader(data)\n",
    "for item in metrics_data:\n",
    "    acc = item['acc']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = [6,7,8,9,10]\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b8e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
